# Lecture 3: Orthonormal Columns in Q Give $Q^{'}Q=I$

## Orthonormal Matrixs Q

### Fundamental properties

When we say that $Q$ is an ==orthonormal matrix==, we means that:
$$
Q^TQ=I
$$
Q doesn't have to be square.

Orthonormal matrix $Q$ always has orthonormal columns $q_i$:
$$
Q = \begin{bmatrix}
| &  & | \\
q_1 &...  & q_n \\
| &  & |
\end{bmatrix}
$$
Apparently:
$$
Q^TQ
=\begin{bmatrix}
- & q_1^T & - \\
 &...  &  \\
- & q_n^T & -
\end{bmatrix}
\begin{bmatrix}
| &  & | \\
q_1 &...  & q_n \\
| &  & |
\end{bmatrix}=I
$$
* The ortho part means $q_i^Tq_j = 0\ ,i\neq j$
* The normal part means $q_i^Tq_j \neq 0\ ,i= j$

When $Q$ is a square matrix,  we say $Q$ is an ==orthogonal matrix==(正交阵！), and
$$
1.\ QQ^T=I\\
2.\ Q^T = Q^{-1}
$$
If $Q$ is not square, $QQ^T$ may not be equal to $I$.

**Q: How to find an orthogonal matrix?**

### Start two by two

two by two orthonormal matrix examples:

1.  $Q = \begin{bmatrix}
   cos\theta & -sin\theta \\
   sin\theta & cos\theta
   \end{bmatrix}$

   $\begin{bmatrix}
   cos\theta \\
   sin\theta 
   \end{bmatrix}$ is a unit vector which is normalized($cos^2\theta+sin^2\theta = 1$), so is the second column.

   It is a ==rotation== of the whole plane by theta.

   ![img](https://images2017.cnblogs.com/blog/47448/201712/47448-20171205160009784-2017209159.png)

   > The important property:
   >
   > ​    orthogonal matrix Q (the rotation) doesn't  change length. <font color='red'>正交/酉变换保模长！！！</font>
   >
   > ​	For any x, $||Qx||=||x||$.

   Proof:
   $$
   ||Qx||^2=(Qx)^T(Qx)=x^TQ^TQx=x^Tx=||x||^2​
   $$
   
2. $Q = \begin{bmatrix}
   cos\theta & sin\theta \\
   sin\theta & -cos\theta
   \end{bmatrix}$

   symmetric, not a rotation matrix any more. It is a ==reflection matrix==, and the mirror is the line $\frac{\theta}{2}$, take $\begin{bmatrix}1\\0\end{bmatrix}$ and $\begin{bmatrix}0\\1\end{bmatrix}$ as examples and try it.


## Several Families of orthogonal matrixs

### 1. Householder

Householder reflections are a bunch of reflections found by Householder, which start with $u^Tu=1$, $H =I-2uu^T$, Q is one of them.

$uu^T$ is symmetric, given $||u||=1$.

$H$ is orthogonal and ==symmetric==. 
$$
H^TH=(I-2uu^T)^T(I-2uu^T)=I-4uu^T+4uu^Tuu^T = I
$$

Q2 above is one of them, they are better than Gram-Schmidit and we'll use them to make things orthogonal.

### 2. Hadamard

$$
H_2=\frac{1}{\sqrt{2}}\begin{bmatrix}
1 & 1 \\
1 & -1
\end{bmatrix}
$$

$$
H_4=\frac{1}{2}\begin{bmatrix}
1 & 1 & 1 & 1 \\
1 & -1& 1 & -1\\
1 & 1 & -1& -1 \\
1 & -1& -1& 1 \end{bmatrix}=\begin{bmatrix}
H_2 & H_2 \\
H_2 & -H_2
\end{bmatrix}
$$

$$
H_8=\begin{bmatrix}
H_4 & H_4 \\
H_4 & -H_4
\end{bmatrix}
$$

conjecture: matrix with only 1 and -1 is orthogonal is always possible, if $\frac{N}{4}$ is a whole number.

### 3. Wavelet

Wavelet matrixs are self-scaling

Haar wavelet matrixs.1910.
$$
W_4=\begin{bmatrix}
1 & 1 & 1 & 0 \\
1 & 1& -1 & 0\\
1 & -1 & 0& 1 \\
1 & -1& 0& -1 \end{bmatrix}
$$

$$
W_8=orth(\begin{bmatrix}
1 & 1 & 1 & 0 & 1 & 0& 0&  0\\
1 & 1& 1 & 0 & -1 & 0&0 &0 \\
1 & 1 & -1& 0 & 0& 1&0 &0\\
1 & 1& -1& 0 & 0& -1& 0&0\\
1 & -1 & 0 & 1 &0 & 0& 1&0\\
1 & -1 & 0 & 1 & 0& 0& -1&0\\
1 & -1 & 0 & -1 & 0& 0&0 &1\\
1 & -1 & 0 & -1 & 0& 0&0 &-1
\end{bmatrix})
$$



Ingrid Daubechies (1988) found a whole lot of families of wavelet matrixs.

> Connected to next lecture:
>
> The eigenvectors of a ==symmetric/orthogonal matrix== are automatically orthogonal. ——where to find vectors that are orthogonal

### Discrete Fourier Transform

$$
Q_4=\begin{bmatrix}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1 \\
1 & 0 & 0 & 0 \end{bmatrix}
$$

A permutation matrix $Q$ is a reordering of an identity matrix.

Eigenvectors of $Q_4$ are Four Discrete Fourier Transform. These evectors are: 1 orthogonal, 2 tremendously useful--heart of signal processing.

$F$ is the eigenvector of $Q$,  which is a complex matrix. 
$$
F_4=\begin{bmatrix}
1 & 1 & 1 & 1 \\
1 & i & i^2 & i^3\\
1 & i^2 & i^4 & i^6 \\
1 & i^3 & i^6 & i^9 \end{bmatrix}
$$
The heart of signal processing, split a signal into its frequencies. zero frequency for 1st column.

For complex vectors, one vector of a dot product is conjugated(change $i$ to $-i$).

> For an orthogonal matrix Q (real or complex):
>
> $$
> Q^TQ=I\\ Qx=\lambda x\\Qy=\mu y
> $$
>
> We have
> $$
> \overline{x}^Ty=0
> $$

